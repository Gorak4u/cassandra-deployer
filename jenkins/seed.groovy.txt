// This seed job reads all Jenkinsfile definitions from this script and creates
// a separate, parameterized pipeline job for each one.
// The generated jobs assume they will be configured with a Git SCM source.

def folderName = 'Cassandra'

// Ensure the folder exists
folder(folderName)

// =============================================================================
// Helper function to create a pipeline job from a script text
// =============================================================================
def createPipelineJob(String folder, String jobName, String pipelineScript) {
    pipelineJob("${folder}/${jobName}") {
        // The entire pipeline definition is provided as a string
        definition {
            cps {
                script(pipelineScript)
                sandbox()
            }
        }
    }
}


// =============================================================================
// Job Definitions
// =============================================================================

// --- Generic Command Job ---
def commandJobScript = '''
pipeline {
    agent any

    environment {
        // Add common macOS paths for tools like 'qv'
        PATH = "/opt/homebrew/bin:/usr/local/bin:${env.PATH}"
    }

    parameters {
        choice(name: 'NODE_SELECTION_METHOD', choices: ['QV_QUERY', 'NODE_LIST'], description: 'Method for selecting target nodes.')
        string(name: 'QV_QUERY', defaultValue: '-r role_cassandra_pfpt', description: 'The QV query to select nodes.')
        string(name: 'NODE_LIST', defaultValue: '', description: 'A comma-separated list of nodes.')
        string(name: 'CASSY_COMMAND', defaultValue: 'sudo cass-ops health', description: 'The command to run via cassy.sh.')
        booleanParam(name: 'PARALLEL', defaultValue: false, description: 'Run in parallel on all nodes?')
    }

    stages {
        stage('Checkout') {
            steps {
                // This assumes the Jenkins job is configured with a Git SCM source
                checkout scm
            }
        }
        stage('Execute Command') {
            steps {
                script {
                    def node_arg = ""
                    if (params.NODE_SELECTION_METHOD == 'QV_QUERY') {
                        node_arg = "--qv-query '${params.QV_QUERY}'"
                    } else {
                        node_arg = "--nodes '${params.NODE_LIST}'"
                    }
                    
                    def parallel_flag = params.PARALLEL ? '--parallel' : ''

                    sh "chmod +x ./scripts/cassy.sh && ./scripts/cassy.sh ${node_arg} -c '${params.CASSY_COMMAND}' ${parallel_flag}"
                }
            }
        }
    }
}
'''
createPipelineJob(folderName, 'Cassandra - Command', commandJobScript)


// --- Rolling Restart Job ---
def restartJobScript = '''
pipeline {
    agent any

    environment {
        PATH = "/opt/homebrew/bin:/usr/local/bin:${env.PATH}"
    }

    parameters {
        choice(name: 'NODE_SELECTION_METHOD', choices: ['QV_QUERY', 'NODE_LIST'], description: 'Method for selecting target nodes.')
        string(name: 'QV_QUERY', defaultValue: '-r role_cassandra_pfpt -d AWSLAB', description: 'The QV query to select nodes for restart.')
        string(name: 'NODE_LIST', defaultValue: '', description: 'A comma-separated list of nodes for restart.')
    }
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        stage('Execute Rolling Restart') {
            steps {
                script {
                    def node_arg = (params.NODE_SELECTION_METHOD == 'QV_QUERY') ? "--qv-query '${params.QV_QUERY}'" : "--nodes '${params.NODE_LIST}'"
                    sh "chmod +x ./scripts/cassy.sh && ./scripts/cassy.sh --rolling-op restart ${node_arg}"
                }
            }
        }
    }
}
'''
createPipelineJob(folderName, 'Cassandra - Restart', restartJobScript)

// --- Rolling Reboot Job ---
def rebootJobScript = '''
pipeline {
    agent any

    environment {
        PATH = "/opt/homebrew/bin:/usr/local/bin:${env.PATH}"
    }

    parameters {
        choice(name: 'NODE_SELECTION_METHOD', choices: ['QV_QUERY', 'NODE_LIST'], description: 'Method for selecting target nodes.')
        string(name: 'QV_QUERY', defaultValue: '-r role_cassandra_pfpt -d AWSLAB', description: 'The QV query to select nodes for reboot.')
        string(name: 'NODE_LIST', defaultValue: '', description: 'A comma-separated list of nodes for reboot.')
    }
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        stage('Execute Rolling Reboot') {
            steps {
                script {
                    def node_arg = (params.NODE_SELECTION_METHOD == 'QV_QUERY') ? "--qv-query '${params.QV_QUERY}'" : "--nodes '${params.NODE_LIST}'"
                    sh "chmod +x ./scripts/cassy.sh && ./scripts/cassy.sh --rolling-op reboot ${node_arg}"
                }
            }
        }
    }
}
'''
createPipelineJob(folderName, 'Cassandra - Reboot', rebootJobScript)

// --- Rolling Puppet Run Job ---
def puppetRunJobScript = '''
pipeline {
    agent any

    environment {
        PATH = "/opt/homebrew/bin:/usr/local/bin:${env.PATH}"
    }

    parameters {
        choice(name: 'NODE_SELECTION_METHOD', choices: ['QV_QUERY', 'NODE_LIST'], description: 'Method for selecting target nodes.')
        string(name: 'QV_QUERY', defaultValue: '-r role_cassandra_pfpt -d AWSLAB', description: 'The QV query to select nodes for puppet run.')
        string(name: 'NODE_LIST', defaultValue: '', description: 'A comma-separated list of nodes for puppet run.')
    }
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        stage('Execute Rolling Puppet Run') {
            steps {
                script {
                    def node_arg = (params.NODE_SELECTION_METHOD == 'QV_QUERY') ? "--qv-query '${params.QV_QUERY}'" : "--nodes '${params.NODE_LIST}'"
                    sh "chmod +x ./scripts/cassy.sh && ./scripts/cassy.sh --rolling-op puppet ${node_arg}"
                }
            }
        }
    }
}
'''
createPipelineJob(folderName, 'Cassandra - Puppet-run', puppetRunJobScript)

// --- Join Datacenters Job ---
def joinDcsJobScript = '''
pipeline {
    agent any

    environment {
        PATH = "/opt/homebrew/bin:/usr/local/bin:${env.PATH}"
    }

    parameters {
        choice(name: 'NODE_SELECTION_METHOD', choices: ['QV_QUERY', 'NODE_LIST'], description: 'Method for selecting target nodes.')
        string(name: 'OLD_DC_QUERY', defaultValue: '-r role_cassandra_pfpt -d us-east-1', description: 'QV Query for OLD datacenter nodes.')
        string(name: 'NEW_DC_QUERY', defaultValue: '-r role_cassandra_pfpt -d eu-west-1', description: 'QV Query for NEW datacenter nodes.')
        string(name: 'OLD_DC_NODES', defaultValue: '', description: 'Node list for OLD datacenter.')
        string(name: 'NEW_DC_NODES', defaultValue: '', description: 'Node list for NEW datacenter.')
        string(name: 'OLD_DC_NAME', defaultValue: 'us-east-1', description: 'Cassandra name of the OLD datacenter.')
        string(name: 'NEW_DC_NAME', defaultValue: 'eu-west-1', description: 'Cassandra name of the NEW datacenter.')
    }
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        stage('Execute Join Operation') {
            steps {
                script {
                    def old_dc_arg = (params.NODE_SELECTION_METHOD == 'QV_QUERY') ? "--old-dc-query '${params.OLD_DC_QUERY}'" : "--old-dc-nodes '${params.OLD_DC_NODES}'"
                    def new_dc_arg = (params.NODE_SELECTION_METHOD == 'QV_QUERY') ? "--new-dc-query '${params.NEW_DC_QUERY}'" : "--new-dc-nodes '${params.NEW_DC_NODES}'"
                    sh "chmod +x ./scripts/join-cassandra-dcs.sh && ./scripts/join-cassandra-dcs.sh ${old_dc_arg} ${new_dc_arg} --old-dc-name '${params.OLD_DC_NAME}' --new-dc-name '${params.NEW_DC_NAME}' --cassy-path './scripts/cassy.sh'"
                }
            }
        }
    }
}
'''
createPipelineJob(folderName, 'Cassandra - Join', joinDcsJobScript)


// --- Split Datacenters Job ---
def splitDcsJobScript = '''
pipeline {
    agent any

    environment {
        PATH = "/opt/homebrew/bin:/usr/local/bin:${env.PATH}"
    }

    parameters {
        choice(name: 'NODE_SELECTION_METHOD', choices: ['QV_QUERY', 'NODE_LIST'], description: 'Method for selecting target nodes.')
        string(name: 'DC1_QUERY', defaultValue: '-r role_cassandra_pfpt -d us-east-1', description: 'QV Query for first datacenter nodes.')
        string(name: 'DC2_QUERY', defaultValue: '-r role_cassandra_pfpt -d eu-west-1', description: 'QV Query for second datacenter nodes.')
        string(name: 'DC1_NODES', defaultValue: '', description: 'Node list for first datacenter.')
        string(name: 'DC2_NODES', defaultValue: '', description: 'Node list for second datacenter.')
        string(name: 'DC1_NAME', defaultValue: 'us-east-1', description: 'Cassandra name of the first datacenter.')
        string(name: 'DC2_NAME', defaultValue: 'eu-west-1', description: 'Cassandra name of the second datacenter.')
    }
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        stage('Execute Split Operation') {
            steps {
                script {
                    def dc1_arg = (params.NODE_SELECTION_METHOD == 'QV_QUERY') ? "--dc1-query '${params.DC1_QUERY}'" : "--dc1-nodes '${params.DC1_NODES}'"
                    def dc2_arg = (params.NODE_SELECTION_METHOD == 'QV_QUERY') ? "--dc2-query '${params.DC2_QUERY}'" : "--dc2-nodes '${params.DC2_NODES}'"
                    sh "chmod +x ./scripts/split-cassandra-dcs.sh && ./scripts/split-cassandra-dcs.sh ${dc1_arg} ${dc2_arg} --dc1-name '${params.DC1_NAME}' --dc2-name '${params.DC2_NAME}' --cassy-path './scripts/cassy.sh'"
                }
            }
        }
    }
}
'''
createPipelineJob(folderName, 'Cassandra - Split', splitDcsJobScript)


// --- Rename Cluster Job ---
def renameClusterJobScript = '''
pipeline {
    agent any

    environment {
        PATH = "/opt/homebrew/bin:/usr/local/bin:${env.PATH}"
    }

    parameters {
        choice(name: 'NODE_SELECTION_METHOD', choices: ['QV_QUERY', 'NODE_LIST'], description: 'Method for selecting target nodes.')
        string(name: 'QV_QUERY', defaultValue: '-r role_cassandra_pfpt -d us-east-1', description: 'QV Query for ALL nodes in the cluster.')
        string(name: 'NODE_LIST', defaultValue: '', description: 'Node list for ALL nodes in the cluster.')
        string(name: 'OLD_NAME', defaultValue: 'MyProductionCluster', description: 'The CURRENT cluster name.')
        string(name: 'NEW_NAME', defaultValue: 'MyPrimaryCluster', description: 'The NEW desired cluster name.')
    }
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        stage('Execute Rename Operation') {
            steps {
                script {
                    def node_arg = (params.NODE_SELECTION_METHOD == 'QV_QUERY') ? "--qv-query '${params.QV_QUERY}'" : "--nodes '${params.NODE_LIST}'"
                    sh "chmod +x ./scripts/rename-cassandra-cluster.sh && ./scripts/rename-cassandra-cluster.sh ${node_arg} --old-name '${params.OLD_NAME}' --new-name '${params.NEW_NAME}' --cassy-path './scripts/cassy.sh'"
                }
            }
        }
    }
}
'''
createPipelineJob(folderName, 'Cassandra - Rename', renameClusterJobScript)


// --- Compaction Job ---
def compactionJobScript = '''
pipeline {
    agent any

    environment {
        PATH = "/opt/homebrew/bin:/usr/local/bin:${env.PATH}"
    }

    parameters {
        choice(name: 'NODE_SELECTION_METHOD', choices: ['QV_QUERY', 'NODE_LIST'], description: 'Method for selecting target nodes.')
        string(name: 'QV_QUERY', defaultValue: '-r role_cassandra_pfpt', description: 'The QV query to select nodes.')
        string(name: 'NODE_LIST', defaultValue: '', description: 'A comma-separated list of nodes.')
        string(name: 'KEYSPACE', defaultValue: '', description: '(Optional) The keyspace to compact. Leave blank for all.')
        string(name: 'TABLES', defaultValue: '', description: '(Optional) Space-separated list of tables. Requires KEYSPACE.')
        string(name: 'NODETOOL_OPTIONS', defaultValue: '', description: '(Optional) Extra options to pass to nodetool compact (e.g., "--split-output").')
        booleanParam(name: 'PARALLEL', defaultValue: false, description: 'Run compaction in parallel on all nodes?')
    }
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        stage('Execute Compaction') {
            steps {
                script {
                    def node_arg = (params.NODE_SELECTION_METHOD == 'QV_QUERY') ? "--qv-query '${params.QV_QUERY}'" : "--nodes '${params.NODE_LIST}'"
                    def parallel_flag = params.PARALLEL ? '--parallel' : ''
                    
                    def cass_ops_command = "sudo /usr/local/bin/cass-ops compact"
                    if (params.NODETOOL_OPTIONS) {
                        cass_ops_command += " --nodetool-options '${params.NODETOOL_OPTIONS}'"
                    }
                    if (params.KEYSPACE) {
                        cass_ops_command += " -k ${params.KEYSPACE}"
                    }
                    if (params.TABLES) {
                       cass_ops_command += " -t " + params.TABLES.replace(' ', ' -t ')
                    }

                    sh "chmod +x ./scripts/cassy.sh && ./scripts/cassy.sh ${node_arg} -c '${cass_ops_command}' ${parallel_flag}"
                }
            }
        }
    }
}
'''
createPipelineJob(folderName, 'Cassandra - Compaction', compactionJobScript)

// --- Garbage Collect Job ---
def garbageCollectJobScript = '''
pipeline {
    agent any

    environment {
        PATH = "/opt/homebrew/bin:/usr/local/bin:${env.PATH}"
    }

    parameters {
        choice(name: 'NODE_SELECTION_METHOD', choices: ['QV_QUERY', 'NODE_LIST'], description: 'Method for selecting target nodes.')
        string(name: 'QV_QUERY', defaultValue: '-r role_cassandra_pfpt', description: 'The QV query to select nodes.')
        string(name: 'NODE_LIST', defaultValue: '', description: 'A comma-separated list of nodes.')
        string(name: 'KEYSPACE', defaultValue: '', description: '(Optional) The keyspace to run GC on. Leave blank for all.')
        string(name: 'TABLES', defaultValue: '', description: '(Optional) Space-separated list of tables. Requires KEYSPACE.')
        string(name: 'NODETOOL_OPTIONS', defaultValue: '', description: '(Optional) Extra options for nodetool garbagecollect (e.g., "-g CELL").')
        booleanParam(name: 'PARALLEL', defaultValue: false, description: 'Run garbage collection in parallel on all nodes?')
    }
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        stage('Execute Garbage Collect') {
            steps {
                script {
                    def node_arg = (params.NODE_SELECTION_METHOD == 'QV_QUERY') ? "--qv-query '${params.QV_QUERY}'" : "--nodes '${params.NODE_LIST}'"
                    def parallel_flag = params.PARALLEL ? '--parallel' : ''

                    def cass_ops_command = "sudo /usr/local/bin/cass-ops garbage-collect"
                    if (params.NODETOOL_OPTIONS) {
                        cass_ops_command += " --nodetool-options '${params.NODETOOL_OPTIONS}'"
                    }
                    if (params.KEYSPACE) {
                        cass_ops_command += " -k ${params.KEYSPACE}"
                    }
                    if (params.TABLES) {
                       cass_ops_command += " -t " + params.TABLES.replace(' ', ' -t ')
                    }
                    
                    sh "chmod +x ./scripts/cassy.sh && ./scripts/cassy.sh ${node_arg} -c '${cass_ops_command}' ${parallel_flag}"
                }
            }
        }
    }
}
'''
createPipelineJob(folderName, 'Cassandra - Garbage-Collect', garbageCollectJobScript)
